{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## BIGQUERY\n",
    "import polars as pl\n",
    "from google.cloud import bigquery, bigquery_storage\n",
    "\n",
    "PROJECT = 'dmecoyfin-250928192534125'\n",
    "client = bigquery.Client(PROJECT)\n",
    "\n",
    "job = client.query(query)\n",
    "bqstorage_client = bigquery_storage.BigQueryReadClient()\n",
    "\n",
    "query = 'SELECT * from c02_delta where foto_mes in (202105,202106,202107, 202108)'\n",
    "\n",
    "job = client.query(query)\n",
    "\n",
    "# Uso Storage API para traer Arrow más rápido\n",
    "arrow_table = job.result().to_arrow(bqstorage_client=bqstorage_client)\n",
    "df_pl = pl.from_arrow(arrow_table)\n",
    "import src.config as config\n",
    "import re\n",
    "from google.cloud import bigquery\n",
    "from src.loader import select_data_c02\n",
    "from src.features import get_numeric_columns_pl, creation_lags, creation_deltas\n",
    "\n",
    "data = select_data_c02([202102])\n",
    "# Columnas a excluir\n",
    "exclude_cols = [\"numero_de_cliente\", \"foto_mes\", \"clase_binaria1\", \"clase_binaria2\", \"clase_peso\"]\n",
    "# Creo array con columnas numéricas\n",
    "numeric_cols = get_numeric_columns_pl(data, exclude_cols=exclude_cols)\n",
    "\n",
    "# Creo tabla con lags\n",
    "creation_lags(numeric_cols, config.NUN_WINDOW_LOAD)\n",
    "\n",
    "# Creo tabla con deltas\n",
    "creation_deltas(numeric_cols, config.NUN_WINDOW_LOAD)\n",
    "\n",
    "\n",
    "def generate_average_delta_query(project_id, dataset_id, table_id, partition_date_str):\n",
    "    \"\"\"\n",
    "    Genera una consulta SQL para calcular el promedio de todas las columnas\n",
    "    que terminan en _delta_1 a _delta_5 para una fecha de partición específica.\n",
    "    \"\"\"\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    table_path = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "    # 1. Obtener todos los nombres de columnas de la tabla\n",
    "    table = client.get_table(table_path)\n",
    "    all_columns = [field.name for field in table.schema]\n",
    "\n",
    "    # 2. Identificar las columnas base (ej. 'campo_a', 'otro_campo')\n",
    "    #    Asumimos que todas las columnas que terminan en _delta_X tienen un prefijo común.\n",
    "    #    Filtramos solo las columnas que tienen el patrón de delta\n",
    "    delta_columns = [col for col in all_columns if re.search(r'_delta_[1-5]$', col)]\n",
    "\n",
    "    # 3. Agrupar las columnas por su número de delta\n",
    "    deltas_by_level = {i: [] for i in range(1, 6)}\n",
    "    for col in delta_columns:\n",
    "        # Extraer el nivel del delta (1, 2, 3, 4 o 5) del final del nombre de la columna\n",
    "        match = re.search(r'_delta_([1-5])$', col)\n",
    "        if match:\n",
    "            level = int(match.group(1))\n",
    "            deltas_by_level[level].append(col)\n",
    "\n",
    "    # 4. Generar las cláusulas AVG para la consulta SQL\n",
    "    avg_expressions = []\n",
    "    for level in sorted(deltas_by_level.keys()):\n",
    "        cols_at_level = deltas_by_level[level]\n",
    "        if cols_at_level:\n",
    "            # Calcular el promedio de las columnas en este nivel de delta\n",
    "            # La sintaxis de BigQuery para promediar múltiples columnas es compleja,\n",
    "            # así que usamos la media de los promedios individuales o pivotamos.\n",
    "            # La mejor forma es calcular el promedio de cada columna por separado.\n",
    "\n",
    "            # Lista de AVG individuales: AVG(col_1_delta_5), AVG(col_2_delta_5), ...\n",
    "            individual_avgs = [f\"AVG(`{col}`)\" for col in cols_at_level]\n",
    "\n",
    "            # Combinamos todos los promedios individuales en un solo cálculo de media global para ese nivel de delta\n",
    "            # Esto es lo que solicitó el usuario: \"para cada campo con delta_5 calcule su promedio\"\n",
    "\n",
    "            for col in cols_at_level:\n",
    "                avg_expressions.append(f\"AVG(`{col}`) AS `{col}_avg`\")\n",
    "\n",
    "    # 5. Ensamblar la consulta SQL final\n",
    "    #    Asumimos que la tabla está particionada por una columna llamada 'fecha_particion'\n",
    "    #    o similar, y que el valor es '202108'.\n",
    "    query = f\"\"\"\n",
    "    CREATE TABLE `{config.BQ_PROJECT}.{config.BQ_DATASET}.{table_id}_avg_delta_202108` AS\n",
    "{\",\\n\".join([\"      \" + expr for expr in avg_expressions])}\n",
    "    FROM\n",
    "        `{table_path}`\n",
    "    WHERE\n",
    "foto_mes = 202108    \"\"\"\n",
    "\n",
    "    return query\n",
    "\n",
    "\n",
    "# --- Uso del script ---\n",
    "\n",
    "# Reemplaza estos valores con los detalles de tu proyecto, conjunto de datos y tabla\n",
    "PROJECT_ID = config.BQ_PROJECT\n",
    "DATASET_ID = config.BQ_DATASET\n",
    "TABLE_ID = \"c02_delta\"\n",
    "PARTITION_MONTH = \"202108\"  # El mes que quieres analizar\n",
    "\n",
    "try:\n",
    "    sql_query = generate_average_delta_query(PROJECT_ID, DATASET_ID, TABLE_ID, PARTITION_MONTH)\n",
    "    print(\"--- Consulta SQL Generada ---\")\n",
    "    print(sql_query)\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    # Opcional: Ejecutar la consulta directamente en BigQuery (descomentar para usar)\n",
    "    client = bigquery.Client(project=config.BQ_PROJECT)\n",
    "    # print(\"Ejecutando consulta en BigQuery...\")\n",
    "    query_job = client.query(sql_query)\n",
    "    results = query_job.result()\n",
    "    # print(\"Resultados:\")\n",
    "    # for row in results:\n",
    "    #     print(row)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"\\nOcurrió un error al intentar obtener el esquema de la tabla. Asegúrate de que las credenciales y los nombres son correctos. Error: {e}\")\n",
    "\n",
    "\n",
    "def generate_average_delta_query_pivot(project_id, dataset_id, table_id, partition_date_str):\n",
    "    \"\"\"\n",
    "    Genera una consulta SQL para calcular el promedio de todas las columnas\n",
    "    que terminan en _delta_1 a _delta_5, y pivota el resultado.\n",
    "    \"\"\"\n",
    "    # Usaremos un cliente simulado si no estás en un entorno con credenciales activas\n",
    "    # client = bigquery.Client(project=project_id)\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    table_path = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "    # 1. Obtener todos los nombres de columnas de la tabla\n",
    "    table = client.get_table(table_path)\n",
    "    all_columns = [field.name for field in table.schema]\n",
    "\n",
    "    # 2. Identificar las columnas base (ej. 'campo_a', 'otro_campo')\n",
    "    #    Asumimos que todas las columnas que terminan en _delta_X tienen un prefijo común.\n",
    "    #    Filtramos solo las columnas que tienen el patrón de delta\n",
    "    delta_columns = [col for col in all_columns if re.search(r'_delta_[1-5]$',\n",
    "                                                             col)]  # --------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # 1. Identificar las columnas delta y sus bases\n",
    "    delta_columns = [col for col in all_columns if re.search(r'_delta_[1-5]$', col)]\n",
    "\n",
    "    # Diccionario para mapear nombre base a una lista de sus deltas [d1, d2, d3, d4, d5]\n",
    "    base_fields = {}\n",
    "    for col in delta_columns:\n",
    "        # Usamos regex para separar el nombre base y el sufijo delta\n",
    "        match = re.search(r'^(.*)_delta_([1-5])$', col)\n",
    "        if match:\n",
    "            base_name = match.group(1)\n",
    "            delta_level = int(match.group(2))\n",
    "            if base_name not in base_fields:\n",
    "                base_fields[base_name] = [None] * 5\n",
    "            base_fields[base_name][delta_level - 1] = col\n",
    "\n",
    "    # 2. Generar la subconsulta que calcula los promedios globales por columna\n",
    "    # Es importante mantener los nombres de columna originales para el UNPIVOT\n",
    "    avg_expressions = [f\"AVG(`{col}`) as `{col}`\" for col in delta_columns]\n",
    "    avg_select_list = \",\\n\".join([\"      \" + expr for expr in avg_expressions])\n",
    "\n",
    "    subquery_alias = \"GlobalAvgs\"\n",
    "    partition_date_str = \"202108\"  # Usamos la fecha que tenías en la query\n",
    "\n",
    "    # 3. Generar la consulta SQL final utilizando UNPIVOT y PIVOT\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{config.BQ_PROJECT}.{config.BQ_DATASET}.deltas_202108_zscore` AS\n",
    "    WITH {subquery_alias} AS (\n",
    "        SELECT\n",
    "{avg_select_list}\n",
    "        FROM\n",
    "            `{table_path}`\n",
    "        WHERE\n",
    "            foto_mes = {partition_date_str}\n",
    "    ),\n",
    "    UnpivotedAvgs AS (\n",
    "        -- Despivota los resultados de los promedios globales\n",
    "        SELECT\n",
    "            REPLACE(REGEXP_EXTRACT(col_name, r'^(.*)_delta_[0-9]+$'), '`', '') AS field_name_base,\n",
    "            CAST(REGEXP_EXTRACT(col_name, r'_delta_([0-9]+)$') AS INT64) AS delta_level,\n",
    "            avg_value\n",
    "        FROM\n",
    "            {subquery_alias}\n",
    "        UNPIVOT(avg_value FOR col_name IN ({\", \".join([f\"`{col}`\" for col in delta_columns])}))\n",
    "    ),\n",
    "    StandardizedAvgs AS (\n",
    "        -- Aplica la estandarización Z-score a los promedios\n",
    "        SELECT\n",
    "            field_name_base,\n",
    "            delta_level,\n",
    "            avg_value,\n",
    "            -- Calcula (Valor - Media) / Desviación Estándar para cada nivel de delta\n",
    "            (avg_value - AVG(avg_value) OVER (PARTITION BY delta_level)) / STDDEV(avg_value) OVER (PARTITION BY delta_level) AS z_score\n",
    "        FROM\n",
    "            UnpivotedAvgs\n",
    "    )\n",
    "    -- Pivota los Z-scores para obtener el formato final deseado\n",
    "    SELECT\n",
    "        field_name_base AS nombre_campo,\n",
    "        AVG(IF(delta_level = 1, z_score, NULL)) AS delta_1,\n",
    "        AVG(IF(delta_level = 2, z_score, NULL)) AS delta_2,\n",
    "        AVG(IF(delta_level = 3, z_score, NULL)) AS delta_3,\n",
    "        AVG(IF(delta_level = 4, z_score, NULL)) AS delta_4,\n",
    "        AVG(IF(delta_level = 5, z_score, NULL)) AS delta_5\n",
    "    FROM\n",
    "        StandardizedAvgs\n",
    "    GROUP BY\n",
    "        nombre_campo\n",
    "    \"\"\"\n",
    "\n",
    "    return query\n",
    "\n",
    "\n",
    "try:\n",
    "    sql_query = generate_average_delta_query_pivot(PROJECT_ID, DATASET_ID, TABLE_ID, PARTITION_MONTH)\n",
    "    print(\"--- Consulta SQL Generada ---\")\n",
    "    print(sql_query)\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    # Opcional: Ejecutar la consulta directamente en BigQuery (descomentar para usar)\n",
    "    client = bigquery.Client(project=config.BQ_PROJECT)\n",
    "    # print(\"Ejecutando consulta en BigQuery...\")\n",
    "    query_job = client.query(sql_query)\n",
    "    results = query_job.result()\n",
    "    # print(\"Resultados:\")\n",
    "    # for row in results:\n",
    "    #     print(row)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"\\nOcurrió un error al intentar obtener el esquema de la tabla. Asegúrate de que las credenciales y los nombres son correctos. Error: {e}\")\n",
    "\n",
    "\n",
    "## DELTAS PARA VARIOS FOTO MES\n",
    "def generate_average_delta_query_multi_month(project_id, dataset_id, table_id):\n",
    "    \"\"\"\n",
    "    Genera una consulta SQL para calcular y estandarizar los promedios de delta para dos meses,\n",
    "    manteniendo el foto_mes en la tabla final.\n",
    "    \"\"\"\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    table_path = f\"{project_id}.{dataset_id}.{table_id}\"\n",
    "\n",
    "    # 1. Obtener todos los nombres de columnas de la tabla\n",
    "    table = client.get_table(table_path)\n",
    "    all_columns = [field.name for field in table.schema]\n",
    "    # --------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # 1. Identificar las columnas delta y sus bases\n",
    "    delta_columns = [col for col in all_columns if re.search(r'_delta_[1-5]$', col)]\n",
    "    # Lista de nombres de columnas sin comillas invertidas para el UNPIVOT\n",
    "    delta_columns_unquoted = [f\"`{col}`\" for col in delta_columns]\n",
    "\n",
    "    # 2. Generar la consulta SQL final\n",
    "    query = f\"\"\"\n",
    "    CREATE TABLE `{config.BQ_PROJECT}.{config.BQ_DATASET}.deltas_multi_meses_zscore` AS\n",
    "    WITH MonthlyAvgs AS (\n",
    "        -- Calcula los promedios por mes y por columna delta\n",
    "        SELECT\n",
    "            foto_mes,\n",
    "            {\",\\n      \".join([f\"AVG(`{col}`) as `{col}`\" for col in delta_columns])}\n",
    "        FROM\n",
    "            `{table_path}`\n",
    "        WHERE\n",
    "            foto_mes IN (202105,202106,202107, 202108)\n",
    "        GROUP BY\n",
    "            foto_mes\n",
    "    ),\n",
    "    UnpivotedMonthlyAvgs AS (\n",
    "        -- Despivota los resultados de los promedios mensuales\n",
    "        SELECT\n",
    "            foto_mes,\n",
    "            -- Extrae el nombre base (ej. 'edad') como 'feature'\n",
    "            REPLACE(REGEXP_EXTRACT(col_name, r'^(.*)_delta_[0-9]+$'), '`', '') AS feature,\n",
    "            -- Extrae el nivel del delta (ej. 1)\n",
    "            CAST(REGEXP_EXTRACT(col_name, r'_delta_([0-9]+)$') AS INT64) AS delta_level,\n",
    "            avg_value\n",
    "        FROM\n",
    "            MonthlyAvgs\n",
    "        UNPIVOT(avg_value FOR col_name IN ({\", \".join(delta_columns_unquoted)}))\n",
    "    ),\n",
    "    StandardizedAvgs AS (\n",
    "        -- Aplica la estandarización Z-score.\n",
    "        -- PARTITION BY delta_level asegura que estandarizamos 'delta_1' contra todos los 'delta_1'\n",
    "        SELECT\n",
    "            foto_mes,\n",
    "            feature,\n",
    "            delta_level,\n",
    "            avg_value,\n",
    "            (avg_value - AVG(avg_value) OVER (PARTITION BY delta_level)) / NULLIF(STDDEV(avg_value) OVER (PARTITION BY delta_level), 0) AS z_score\n",
    "        FROM\n",
    "            UnpivotedMonthlyAvgs\n",
    "    )\n",
    "    -- Pivota los Z-scores para obtener el formato final deseado\n",
    "    SELECT\n",
    "        foto_mes,\n",
    "        feature,\n",
    "        AVG(IF(delta_level = 1, z_score, NULL)) AS delta_1,\n",
    "        AVG(IF(delta_level = 2, z_score, NULL)) AS delta_2,\n",
    "        AVG(IF(delta_level = 3, z_score, NULL)) AS delta_3,\n",
    "        AVG(IF(delta_level = 4, z_score, NULL)) AS delta_4,\n",
    "        AVG(IF(delta_level = 5, z_score, NULL)) AS delta_5\n",
    "    FROM\n",
    "        StandardizedAvgs\n",
    "    GROUP BY\n",
    "        foto_mes, feature\n",
    "    ORDER BY\n",
    "        foto_mes, feature\n",
    "    \"\"\"\n",
    "\n",
    "    return query\n",
    "\n",
    "\n",
    "try:\n",
    "    sql_query = generate_average_delta_query_multi_month(PROJECT_ID, DATASET_ID, TABLE_ID)\n",
    "    print(\"--- Consulta SQL Generada ---\")\n",
    "    print(sql_query)\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    # Opcional: Ejecutar la consulta directamente en BigQuery (descomentar para usar)\n",
    "    client = bigquery.Client(project=config.BQ_PROJECT)\n",
    "    # print(\"Ejecutando consulta en BigQuery...\")\n",
    "    query_job = client.query(sql_query)\n",
    "    results = query_job.result()\n",
    "    # print(\"Resultados:\")\n",
    "    # for row in results:\n",
    "    #     print(row)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"\\nOcurrió un error al intentar obtener el esquema de la tabla. Asegúrate de que las credenciales y los nombres son correctos. Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
